import streamlit as st
import google.generativeai as genai
import os
import re
import pandas as pd
from dotenv import load_dotenv
from utils import get_index_context

# 0. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 1. Gemini API ì„¤ì •
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("Google API Keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=api_key)

# 2. ë¬¸ì„œ ë§í¬ ë¡œë“œ (Excel ìµœìš°ì„ )
def load_document_links():
    links = {}
    try:
        excel_path = 'document_links.xlsx'
        if not os.path.exists(excel_path):
            excel_path = os.path.join(os.path.dirname(__file__), '..', 'document_links.xlsx')
            
        if os.path.exists(excel_path):
            df = pd.read_excel(excel_path)
            for _, row in df.iterrows():
                inst = str(row['equipment']).upper().strip()
                raw_num = str(row['sheet_no']).strip()
                if '.' in raw_num: raw_num = raw_num.split('.')[0]
                num = raw_num.zfill(3)
                lang = str(row['language']).upper().strip()
                url = str(row['link']).strip()
                if url and url != 'nan':
                    links[(inst, num, lang)] = url
    except Exception:
        pass
    return links

DOCUMENT_LINKS = load_document_links()

# 3. ì¸ê³µì§€ëŠ¥ ì‘ë‹µ í•¨ìˆ˜
def get_gemini_response(user_prompt):
    # ëŒ€í™” ë§¥ë½ êµ¬ì„±
    history = ""
    if "messages" in st.session_state:
        for m in st.session_state.messages[-4:]:
            role = "User" if m["role"] == "user" else "Assistant"
            history += f"{role}: {m['content']}\n"

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì³ì„œ ì˜¤ë¥˜ ë°©ì§€)
    full_text_prompt = f"""
    ## QC ë¶„ì„ê¸°ê¸° ì§€ì¹¨ì„œ ì•ˆë‚´ ë´‡
    
    [ì§€ì¹¨]
    1. ë°˜ë“œì‹œ ì œê³µëœ INDEX DATAë§Œ ê·¼ê±°ë¡œ ë‹µë³€í•  ê²ƒ.
    2. ìœ„ì¹˜ ì •ë³´(Sheet No, Title, Instrument) ì™¸ì˜ ì¡°ì–¸ì€ ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ.
    3. í•œêµ­ì–´ ì§ˆë¬¸ì—” í•œêµ­ì–´ë¡œ, ì˜ì–´ ì§ˆë¬¸ì—” ì˜ì–´ë¡œ ë‹µë³€í•  ê²ƒ.
    4. ì¶œë ¥ í˜•ì‹: [ì¥ë¹„ëª…]-[ë²ˆí˜¸3ìë¦¬] (ì˜ˆ: HPLC-029)

    [INDEX DATA]
    {st.session_state.index_context}

    [ëŒ€í™” ê¸°ë¡]
    {history}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_prompt}
    """
    
    # ëª¨ë¸ ì„¤ì • (ê°€ì¥ ì•ˆì •ì ì¸ ìµœì‹  ëª…ì¹­ ì‚¬ìš©)
    try:
        model = genai.GenerativeModel("gemini-1.5-flash-latest")
        response = model.generate_content(full_text_prompt)
        text = response.text
    except Exception as e:
        # ëª¨ë¸ ëª…ì¹­ í˜¸í™˜ì„± ëŒ€ë¹„ (ì‹¤íŒ¨ ì‹œ ì°¨ì„ ì±… ëª¨ë¸ ì‚¬ìš©)
        model = genai.GenerativeModel("gemini-pro")
        response = model.generate_content(full_text_prompt)
        text = response.text

    # ë§í¬ ë§¤ì¹­ ë° í¬ë§·íŒ…
    lang = "KR" if any(0xAC00 <= ord(c) <= 0xD7A3 for c in user_prompt) else "EN"
    matches = re.findall(r'([A-Za-z]+)-(\d{3})', text)
    unique_links = set()
    link_md = ""
    for inst, num in matches:
        key = (inst.upper(), num, lang)
        if key in DOCUMENT_LINKS:
            url = DOCUMENT_LINKS[key]
            if url not in unique_links:
                label = f"{inst}-{num} ë¬¸ì„œ ë°”ë¡œê°€ê¸°" if lang == "KR" else f"View Document {inst}-{num}"
                link_md += f"\n\nğŸ”— [{label}]({url})"
                unique_links.add(url)
    
    footer = "\n\n---\nğŸ’¡ ë¬¸ì„œë¥¼ ëª» ì°¾ìœ¼ì…¨ë‚˜ìš”? [**ì „ì²´ í´ë” ê°€ê¸°**](https://works.do/FYhb6GY)" if lang=="KR" else "\n\n---\nğŸ’¡ [**Check Entire Folder**](https://works.do/FYhb6GY)"
    return text + link_md + footer

# 4. Streamlit UI
st.set_page_config(page_title="MSÂ·TS Guide Chatbot", page_icon="ğŸ»")

# CSS ë””ìì¸
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Pretendard', sans-serif; }
    .header-container {
        background: linear-gradient(135deg, #3B28CC 0%, #E062E6 100%);
        padding: 2.5rem 1.5rem; border-radius: 0 0 20px 20px; color: white; margin-bottom: 2rem;
    }
    [data-testid="stChatMessage"] { border-radius: 15px; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="header-container"><h1>MSÂ·TS Guide Chatbot</h1><p>ì¦ìƒì„ ì…ë ¥í•˜ì‹œë©´ ê´€ë ¨ ì§€ì¹¨ì„œ ìœ„ì¹˜ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.</p></div>', unsafe_allow_html=True)

if "messages" not in st.session_state: st.session_state.messages = []
if "index_context" not in st.session_state:
    st.session_state.index_context = get_index_context()

# ì±„íŒ… í‘œì‹œ
for m in st.session_state.messages:
    with st.chat_message(m["role"], avatar="ğŸ»" if m["role"]=="assistant" else "ğŸ§‘â€ğŸ’»"):
        st.markdown(m["content"])

# ìŠ¤íƒ€í„° ë²„íŠ¼
if not st.session_state.messages:
    st.info("ğŸ’¡ ì•„ë˜ ì˜ˆì‹œë¥¼ í´ë¦­í•˜ê±°ë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    c1, c2 = st.columns(2)
    def fast_query(q):
        st.session_state.messages.append({"role": "user", "content": q})
        with st.chat_message("assistant", avatar="ğŸ»"):
            res = get_gemini_response(q)
            st.markdown(res)
            st.session_state.messages.append({"role": "assistant", "content": res})
        st.rerun()
    if c1.button("HPLC í”¼í¬ ê°ˆë¼ì§ í•´ê²°", use_container_width=True): fast_query("HPLC í”¼í¬ ê°ˆë¼ì§ í•´ê²°ë°©ë²• ì•Œë ¤ì¤˜")
    if c2.button("HPLC ì¬í˜„ì„±ì´ ì•ˆ ì¢‹ì•„", use_container_width=True): fast_query("HPLC ê²°ê³¼ ì¬í˜„ì„±ì´ ì•ˆ ì¢‹ì•„")

# ì±„íŒ… ì…ë ¥
if prompt := st.chat_input("ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš”..."):
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"): st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("assistant", avatar="ğŸ»"):
        res = get_gemini_response(prompt)
        st.markdown(res)
        st.session_state.messages.append({"role": "assistant", "content": res})
